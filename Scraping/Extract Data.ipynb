{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('Data/Active - Wholesale & retail.xlsx', sheetname='Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33791"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Twitter handle + Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pws import Bing\n",
    "from pws import Google\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies=df['Company name'][1000:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean to remove 'limited etc'\n",
    "\n",
    "companies=companies.apply(lambda x: x.replace('PLC', ''))\n",
    "companies=companies.apply(lambda x: x.replace('P L C', ''))\n",
    "companies=companies.apply(lambda x: x.replace('P.L.C.', ''))\n",
    "companies=companies.apply(lambda x: x.replace('LTD', ''))\n",
    "companies=companies.apply(lambda x: x.replace('LIMITED', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "website_links=[]\n",
    "website_links_2=[]\n",
    "twitter_links=[]\n",
    "twitter_links_2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in companies:\n",
    "    try:   \n",
    "        twitter_result=Bing.search(x + 'Twitter', num=2, start=0, sleep=True, country_code='uk')\n",
    "        twitter_links.append(twitter_result['results'][0]['link'])\n",
    "        twitter_links_2.append(twitter_result['results'][1]['link'])\n",
    "    except:\n",
    "        twitter_links.append('error in retrieving twitter')\n",
    "        twitter_links_2.append('error in retrieving twitter')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in companies:\n",
    "    try:   \n",
    "        website_result=Bing.search(x + 'Website', num=2, start=0, sleep=True, country_code='uk')\n",
    "        website_links.append(website_result['results'][0]['link'])\n",
    "        website_links_2.append(website_result['results'][1]['link'])\n",
    "    except:\n",
    "        website_links.append('error in retrieving website')\n",
    "        website_links_2.append('error in retrieving website')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_links_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF=pd.DataFrame({'company': companies, 'Twitter': twitter_links, 'Twitter 2': twitter_links_2,\n",
    "                 'Website': website_links,'Website 2': website_links_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF.to_csv('twitter + sites 1000-1500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Twitter Handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('twitter + sites 1500-2500.csv')\n",
    "df=df.drop({'Unnamed: 0'}, 1)\n",
    "df=df[['company', 'Website', 'Website 2', 'Twitter', 'Twitter 2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectTwitter(row):\n",
    "    if type(row)==str:\n",
    "        if row[8] != 't':\n",
    "            return np.nan\n",
    "        else:\n",
    "            return row\n",
    "    else:\n",
    "        return np.nan\n",
    "df['Twitter']=df['Twitter'].apply(selectTwitter)\n",
    "df['Twitter 2']=df['Twitter 2'].apply(selectTwitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Twitter']=df['Twitter'].fillna(df['Twitter 2'])\n",
    "df=df.drop({'Twitter 2'},1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extracthandle(row):\n",
    "    try:\n",
    "        if type(row)==str:\n",
    "            row= row[20:]\n",
    "\n",
    "            row=re.search(r'\\w+', row)\n",
    "            return row.group()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Twitter']=df['Twitter'].apply(extracthandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2    GCmotors\n",
       "3        None\n",
       "4        None\n",
       "Name: Twitter, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Twitter'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-- 140 twitter handles extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Tweet Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "#consumer_key = \"CJqhuEFhIFfkw1k43htNOnJeX\"\n",
    "#consumer_secret = \"Hm46gor4LVvv4N6X7uzYInHBSaLBBCOmlIoqKxj0YWXnevD8c2\"\n",
    "#access_key = \"64435602-drySR7XgKqQUvawnV9ZPp5ZqxvpGE3dTAKhmAp3q6\"\n",
    "#access_secret = \"F9CoAbW5X3TGv6Z89DK2c84k50GAAFASPuaEcy36dFDaz\"\n",
    "\n",
    "# issieibb\n",
    "#consumer_key = \"XS1yXEmxTiCkXGah3aFyMsMEa\"\n",
    "#consumer_secret = \"Wllivye1lKLMreewdW3fEj7liXJBensvsEsofCUy3fFekDlsnk\"\n",
    "#access_key = \"754056966448750592-fTFelEPHOS1HE54pTQuubJmjfzXwpt2\"\n",
    "#access_secret = \"ctVlg98kB7gl2j7FNsq4xxN28JDngYEiicClYQ1DDVYkH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users=df['Twitter'].dropna(how='any', axis=0)\n",
    "users=users.reset_index()\n",
    "users=users.drop({'index'},1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []  \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print (\"getting tweets before %s\" % (oldest))\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\"), screen_name, tweet.retweet_count, tweet.favorite_count] for tweet in alltweets]\n",
    "    \n",
    "    #write the csv  \n",
    "    with open('Tweets/%s_tweets.csv' % screen_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\", \"User\", 'num_RTs', 'num_Favourites'])\n",
    "        \n",
    "        writer.writerows(outtweets)\n",
    "        print('done')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#users.Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 743895818797748223\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 585411863128756223\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 446041174709522432\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 317006741432831999\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 95582097611300863\n",
      "...1015 tweets downloaded so far\n",
      "getting tweets before 1049310918\n",
      "...1015 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 171389989958074367\n",
      "...6 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 824305863628353535\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 781098282521165823\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 760461450640920575\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 699608814295896067\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 624631519966052352\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 573434033440456703\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 512201816097189888\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 354596163426607103\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 210682863933325311\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 73339729386545151\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 19739060608\n",
      "...2205 tweets downloaded so far\n",
      "getting tweets before 19349175988\n",
      "...2205 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 869941684074893311\n",
      "...383 tweets downloaded so far\n",
      "getting tweets before 849571510931120127\n",
      "...383 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 482545032147501055\n",
      "...2 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 727367372928090111\n",
      "...398 tweets downloaded so far\n",
      "getting tweets before 666328802566529024\n",
      "...596 tweets downloaded so far\n",
      "getting tweets before 567607895521755135\n",
      "...793 tweets downloaded so far\n",
      "getting tweets before 377821610600038400\n",
      "...811 tweets downloaded so far\n",
      "getting tweets before 370167127103504383\n",
      "...811 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 697085986472333311\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 544516515417305087\n",
      "...487 tweets downloaded so far\n",
      "getting tweets before 494824339431510017\n",
      "...487 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 886059720922017791\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 877813279103561727\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 863492729950666753\n",
      "...798 tweets downloaded so far\n",
      "getting tweets before 849377852860637183\n",
      "...998 tweets downloaded so far\n",
      "getting tweets before 840535009945509887\n",
      "...1198 tweets downloaded so far\n",
      "getting tweets before 833344620398526464\n",
      "...1398 tweets downloaded so far\n",
      "getting tweets before 833330487137562624\n",
      "...1598 tweets downloaded so far\n",
      "getting tweets before 826861207449718796\n",
      "...1798 tweets downloaded so far\n",
      "getting tweets before 818755795072544767\n",
      "...1998 tweets downloaded so far\n",
      "getting tweets before 809434601991053311\n",
      "...2197 tweets downloaded so far\n",
      "getting tweets before 801361943521034240\n",
      "...2397 tweets downloaded so far\n",
      "getting tweets before 793360583659839487\n",
      "...2596 tweets downloaded so far\n",
      "getting tweets before 785223649020284927\n",
      "...2796 tweets downloaded so far\n",
      "getting tweets before 775752653603213311\n",
      "...2996 tweets downloaded so far\n",
      "getting tweets before 765098563370098687\n",
      "...3196 tweets downloaded so far\n",
      "getting tweets before 755355022662197248\n",
      "...3198 tweets downloaded so far\n",
      "getting tweets before 755135716942831616\n",
      "...3198 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 723942193568817151\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 644837064849100799\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 548765355360133119\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 426719118633336832\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 321603807966547967\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 211080211024982015\n",
      "...1292 tweets downloaded so far\n",
      "getting tweets before 96136062841257983\n",
      "...1292 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 727399285357047807\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 510343744252829695\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 191919008205910015\n",
      "...729 tweets downloaded so far\n",
      "getting tweets before 17363259983\n",
      "...729 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 854993102548992000\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 840871254785699839\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 826836358346002434\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 805754781365104639\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 790118118064521215\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 774987196902309888\n",
      "...1397 tweets downloaded so far\n",
      "getting tweets before 756085113662935039\n",
      "...1597 tweets downloaded so far\n",
      "getting tweets before 743399764016893951\n",
      "...1797 tweets downloaded so far\n",
      "getting tweets before 727771065708064768\n",
      "...1997 tweets downloaded so far\n",
      "getting tweets before 711950780459323391\n",
      "...2196 tweets downloaded so far\n",
      "getting tweets before 691917961540542463\n",
      "...2396 tweets downloaded so far\n",
      "getting tweets before 647347854437183487\n",
      "...2592 tweets downloaded so far\n",
      "getting tweets before 631478889815121919\n",
      "...2790 tweets downloaded so far\n",
      "getting tweets before 613277951589748735\n",
      "...2989 tweets downloaded so far\n",
      "getting tweets before 600590328903544831\n",
      "...3186 tweets downloaded so far\n",
      "getting tweets before 578232509286105088\n",
      "...3224 tweets downloaded so far\n",
      "getting tweets before 575368225837416447\n",
      "...3224 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 881841057633271809\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 871035583841304575\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 862679598294761471\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 854269654923177984\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 844465531218542591\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 832293332051189761\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 821328046544343039\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 803268242718519295\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 795666652943777792\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 783568414501638143\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 771953399122173951\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 760424917720526847\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 749956983239892992\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 743378380066783232\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 734018640471822336\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 725633394982424575\n",
      "...3223 tweets downloaded so far\n",
      "getting tweets before 724895814162735104\n",
      "...3223 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 850364847648854015\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 826430875688636415\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 801467893049344000\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 778561138309079040\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 756073030414106623\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 735770606977716225\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 720892874162900991\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 704218687650316287\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 692013712681635840\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 679604464291037185\n",
      "...2199 tweets downloaded so far\n",
      "getting tweets before 651360739651940351\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 639396869190324223\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 610412038792347647\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 588946949174382593\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 569820209659437055\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 542978479944654847\n",
      "...3231 tweets downloaded so far\n",
      "getting tweets before 539361335579275263\n",
      "...3231 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 432834762537848831\n",
      "...181 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 802193616605249535\n",
      "...219 tweets downloaded so far\n",
      "getting tweets before 791201032361635839\n",
      "...219 tweets downloaded so far\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 812019965280813055\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 766428182958473216\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 725341068208779263\n",
      "...797 tweets downloaded so far\n",
      "getting tweets before 672613626604224511\n",
      "...997 tweets downloaded so far\n",
      "getting tweets before 549439633852223487\n",
      "...1195 tweets downloaded so far\n",
      "getting tweets before 458273769727864831\n",
      "...1395 tweets downloaded so far\n",
      "getting tweets before 352820055442079745\n",
      "...1595 tweets downloaded so far\n",
      "getting tweets before 188414001393319935\n",
      "...1793 tweets downloaded so far\n",
      "getting tweets before 27957166207\n",
      "...1993 tweets downloaded so far\n",
      "getting tweets before 3401178212\n",
      "...2122 tweets downloaded so far\n",
      "getting tweets before 1289034316\n",
      "...2122 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 849576123562373119\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 814473658769043455\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 762662027722625023\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 707185757845377024\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 639004889620828159\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 517666881680207871\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 448466653823913983\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 376980941001854975\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 324890530767073280\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 295826955574591488\n",
      "...2199 tweets downloaded so far\n",
      "getting tweets before 264041566744743935\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 235296729820430335\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 211028652715032576\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 183125170574204927\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 141810969100820479\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 101752685035921407\n",
      "...3234 tweets downloaded so far\n",
      "getting tweets before 96548259203518463\n",
      "...3234 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 784376340011069439\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 728523407042711551\n",
      "...598 tweets downloaded so far\n",
      "getting tweets before 678972695233601535\n",
      "...798 tweets downloaded so far\n",
      "getting tweets before 639468424310194175\n",
      "...998 tweets downloaded so far\n",
      "getting tweets before 591163368460918783\n",
      "...1141 tweets downloaded so far\n",
      "getting tweets before 542340128140951551\n",
      "...1141 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 37942975183065087\n",
      "...119 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 659127561260130303\n",
      "...307 tweets downloaded so far\n",
      "getting tweets before 628967937982861311\n",
      "...307 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 880398535149195263\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 867477746473205759\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 856575580749410303\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 848843769063636991\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 842287466497380351\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 834049695966175231\n",
      "...1398 tweets downloaded so far\n",
      "getting tweets before 823179538070900735\n",
      "...1598 tweets downloaded so far\n",
      "getting tweets before 810574791392555007\n",
      "...1798 tweets downloaded so far\n",
      "getting tweets before 801413784174739455\n",
      "...1998 tweets downloaded so far\n",
      "getting tweets before 791968553184485375\n",
      "...2198 tweets downloaded so far\n",
      "getting tweets before 780039437635944447\n",
      "...2398 tweets downloaded so far\n",
      "getting tweets before 770998310559686655\n",
      "...2597 tweets downloaded so far\n",
      "getting tweets before 763400996299177983\n",
      "...2794 tweets downloaded so far\n",
      "getting tweets before 754742521608151040\n",
      "...2994 tweets downloaded so far\n",
      "getting tweets before 748403866450952192\n",
      "...3194 tweets downloaded so far\n",
      "getting tweets before 742370830416482304\n",
      "...3214 tweets downloaded so far\n",
      "getting tweets before 741585962518609919\n",
      "...3214 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 707550436153135103\n",
      "...205 tweets downloaded so far\n",
      "getting tweets before 705015857223639039\n",
      "...205 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 475947656720945151\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 225627384731283455\n",
      "...588 tweets downloaded so far\n",
      "getting tweets before 7593378974\n",
      "...588 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 778911789597818879\n",
      "...397 tweets downloaded so far\n",
      "getting tweets before 501698148474310655\n",
      "...597 tweets downloaded so far\n",
      "getting tweets before 431436385049137151\n",
      "...656 tweets downloaded so far\n",
      "getting tweets before 377435037836132351\n",
      "...656 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 29352053270\n",
      "...1 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 885098962096705537\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 878194553940877312\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 872053058645229567\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 862929090915033088\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 854318797238534146\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 842647737883643903\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 832186578554515455\n",
      "...1598 tweets downloaded so far\n",
      "getting tweets before 822428899938365440\n",
      "...1798 tweets downloaded so far\n",
      "getting tweets before 806030644648247295\n",
      "...1998 tweets downloaded so far\n",
      "getting tweets before 799239511070953471\n",
      "...2198 tweets downloaded so far\n",
      "getting tweets before 791178650293047299\n",
      "...2398 tweets downloaded so far\n",
      "getting tweets before 784328251661365247\n",
      "...2598 tweets downloaded so far\n",
      "getting tweets before 775665953661157376\n",
      "...2798 tweets downloaded so far\n",
      "getting tweets before 762904940939472895\n",
      "...2998 tweets downloaded so far\n",
      "getting tweets before 748463771727839231\n",
      "...3198 tweets downloaded so far\n",
      "getting tweets before 737350594671869951\n",
      "...3203 tweets downloaded so far\n",
      "getting tweets before 736921362355359743\n",
      "...3203 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 844191422383235071\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 822217079692623871\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 801802558910107647\n",
      "...796 tweets downloaded so far\n",
      "getting tweets before 788022897340186623\n",
      "...996 tweets downloaded so far\n",
      "getting tweets before 770381896962441216\n",
      "...1195 tweets downloaded so far\n",
      "getting tweets before 768098088741441536\n",
      "...1391 tweets downloaded so far\n",
      "getting tweets before 765292746273918975\n",
      "...1588 tweets downloaded so far\n",
      "getting tweets before 757683252840792065\n",
      "...1785 tweets downloaded so far\n",
      "getting tweets before 752617309156630527\n",
      "...1981 tweets downloaded so far\n",
      "getting tweets before 748245800229212163\n",
      "...2181 tweets downloaded so far\n",
      "getting tweets before 744721682796019712\n",
      "...2380 tweets downloaded so far\n",
      "getting tweets before 739926966124597247\n",
      "...2579 tweets downloaded so far\n",
      "getting tweets before 734572469680537600\n",
      "...2779 tweets downloaded so far\n",
      "getting tweets before 729790445199327232\n",
      "...2977 tweets downloaded so far\n",
      "getting tweets before 727244635731578880\n",
      "...3176 tweets downloaded so far\n",
      "getting tweets before 722178051073830911\n",
      "...3188 tweets downloaded so far\n",
      "getting tweets before 722174461412319231\n",
      "...3188 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 737929360464871423\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 663710350240571391\n",
      "...595 tweets downloaded so far\n",
      "getting tweets before 595610195222474752\n",
      "...792 tweets downloaded so far\n",
      "getting tweets before 521931659399401471\n",
      "...990 tweets downloaded so far\n",
      "getting tweets before 479190542291849215\n",
      "...1190 tweets downloaded so far\n",
      "getting tweets before 428916587887091711\n",
      "...1390 tweets downloaded so far\n",
      "getting tweets before 351986609031352319\n",
      "...1589 tweets downloaded so far\n",
      "getting tweets before 313973965821468671\n",
      "...1789 tweets downloaded so far\n",
      "getting tweets before 281360687710756863\n",
      "...1895 tweets downloaded so far\n",
      "getting tweets before 480286705975295\n",
      "...1895 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 862278300147830783\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 839175820350533632\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 820982185461215231\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 786572971875893248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1000 tweets downloaded so far\n",
      "getting tweets before 750386262754942975\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 715585700146585599\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 693120181153959937\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 646370905137000447\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 603235172062990335\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 568190735780073474\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 522066054781341695\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 474309875036864516\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 427903817443979263\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 378207885211471872\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 341950746129993728\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 316586095993290751\n",
      "...3250 tweets downloaded so far\n",
      "getting tweets before 309770465788964863\n",
      "...3250 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 788290428852371455\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 735093826759630847\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 608696751751577601\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 527371527822778367\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 481168222411296767\n",
      "...1059 tweets downloaded so far\n",
      "getting tweets before 461100876003033087\n",
      "...1059 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 11004679588679679\n",
      "...209 tweets downloaded so far\n",
      "getting tweets before 636683451\n",
      "...209 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 410417189037305855\n",
      "...34 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 882553506577747967\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 875623266722865151\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 872712980936261635\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 863439514198581247\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 857585030159372287\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 854071926481969152\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 846454224837906433\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 841591131439812607\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 834311092318920707\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 826519122347487232\n",
      "...2199 tweets downloaded so far\n",
      "getting tweets before 820947992308023295\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 817715290620493824\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 811961783648944127\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 806436773803028479\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 799249261003210751\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 793454033310719999\n",
      "...3235 tweets downloaded so far\n",
      "getting tweets before 792780475790139392\n",
      "...3235 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 804299447807148032\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 700292436896178175\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 601047131395379201\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 486221908091109375\n",
      "...822 tweets downloaded so far\n",
      "getting tweets before 482581733683253247\n",
      "...822 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 884069783108497407\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 874283908225015807\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 865221397416734719\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 854699800884850687\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 844589253300535295\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 830749411416350719\n",
      "...1398 tweets downloaded so far\n",
      "getting tweets before 775038594385846271\n",
      "...1598 tweets downloaded so far\n",
      "getting tweets before 770339667292065791\n",
      "...1797 tweets downloaded so far\n",
      "getting tweets before 767363475429556223\n",
      "...1997 tweets downloaded so far\n",
      "getting tweets before 753938986893271039\n",
      "...2197 tweets downloaded so far\n",
      "getting tweets before 750217153266286591\n",
      "...2397 tweets downloaded so far\n",
      "getting tweets before 739191996082991103\n",
      "...2597 tweets downloaded so far\n",
      "getting tweets before 715188508462329857\n",
      "...2797 tweets downloaded so far\n",
      "getting tweets before 707568110199554047\n",
      "...2997 tweets downloaded so far\n",
      "getting tweets before 693836422189600767\n",
      "...3197 tweets downloaded so far\n",
      "getting tweets before 644815113317449728\n",
      "...3206 tweets downloaded so far\n",
      "getting tweets before 643514186547527679\n",
      "...3206 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 804281855059120128\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 760769901732597761\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 730329357797855231\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 695567267321528319\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 659708840116490241\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 628896794001453055\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 598419950705901569\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 565548429267308543\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 537643891810639871\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 519794187907366913\n",
      "...2198 tweets downloaded so far\n",
      "getting tweets before 508993511023464447\n",
      "...2398 tweets downloaded so far\n",
      "getting tweets before 499952360572321791\n",
      "...2598 tweets downloaded so far\n",
      "getting tweets before 487597182250663935\n",
      "...2700 tweets downloaded so far\n",
      "getting tweets before 478664400380125184\n",
      "...2700 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 796027008304250879\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 693125964268605439\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 595548528778153983\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 486795431100547071\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 390477946898497535\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 241102292508606463\n",
      "...1299 tweets downloaded so far\n",
      "getting tweets before 67617757604220927\n",
      "...1299 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 444096078875742208\n",
      "...263 tweets downloaded so far\n",
      "getting tweets before 98856922198978559\n",
      "...263 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 141522404815020032\n",
      "...119 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 476043204140085247\n",
      "...396 tweets downloaded so far\n",
      "getting tweets before 428956171391614976\n",
      "...592 tweets downloaded so far\n",
      "getting tweets before 339451223742771199\n",
      "...791 tweets downloaded so far\n",
      "getting tweets before 268795931258929151\n",
      "...856 tweets downloaded so far\n",
      "getting tweets before 258601868429754369\n",
      "...856 tweets downloaded so far\n",
      "done\n",
      "error at intent \n",
      "getting tweets before 878652663109472255\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 862347733411262468\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 854403226598346752\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 839011331227410432\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 828373550058917887\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 820659834018234367\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 813163347042586623\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 804663316123680767\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 798057834084646911\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 789917291269980159\n",
      "...2199 tweets downloaded so far\n",
      "getting tweets before 780698053791588351\n",
      "...2380 tweets downloaded so far\n",
      "getting tweets before 773261331432665089\n",
      "...2580 tweets downloaded so far\n",
      "getting tweets before 768371884526276607\n",
      "...2780 tweets downloaded so far\n",
      "getting tweets before 761994318165008383\n",
      "...2980 tweets downloaded so far\n",
      "getting tweets before 758189937992671231\n",
      "...3180 tweets downloaded so far\n",
      "getting tweets before 754364551185960959\n",
      "...3223 tweets downloaded so far\n",
      "getting tweets before 752049878134583295\n",
      "...3223 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 864793642929704959\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 831500049960026113\n",
      "...597 tweets downloaded so far\n",
      "getting tweets before 798270544395333631\n",
      "...792 tweets downloaded so far\n",
      "getting tweets before 742434737302704127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...989 tweets downloaded so far\n",
      "getting tweets before 705036996469792767\n",
      "...1188 tweets downloaded so far\n",
      "getting tweets before 669102373118283775\n",
      "...1385 tweets downloaded so far\n",
      "getting tweets before 619843607479123968\n",
      "...1580 tweets downloaded so far\n",
      "getting tweets before 600778499218104319\n",
      "...1778 tweets downloaded so far\n",
      "getting tweets before 576346663679307775\n",
      "...1972 tweets downloaded so far\n",
      "getting tweets before 539810067592523775\n",
      "...2168 tweets downloaded so far\n",
      "getting tweets before 515550342084177919\n",
      "...2360 tweets downloaded so far\n",
      "getting tweets before 482104581913329664\n",
      "...2548 tweets downloaded so far\n",
      "getting tweets before 452146457005813759\n",
      "...2746 tweets downloaded so far\n",
      "getting tweets before 433724612674088959\n",
      "...2943 tweets downloaded so far\n",
      "getting tweets before 401384936428806143\n",
      "...3139 tweets downloaded so far\n",
      "getting tweets before 380326911718998015\n",
      "...3172 tweets downloaded so far\n",
      "getting tweets before 377430705925804032\n",
      "...3172 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 832575798993358848\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 755414510123507711\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 687610141160681471\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 642658936869380095\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 605748214332039167\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 570621538808016895\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 536547738289471487\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 498560708360282112\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 476455047648522239\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 451084537012162562\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 423156253582311424\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 396637823962742783\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 361499300825530368\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 333595456347189247\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 303969878975586303\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 284992172971937793\n",
      "...3226 tweets downloaded so far\n",
      "getting tweets before 282121271020511234\n",
      "...3226 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 100678362988683263\n",
      "...300 tweets downloaded so far\n",
      "getting tweets before 826286245\n",
      "...300 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 100678362988683263\n",
      "...300 tweets downloaded so far\n",
      "getting tweets before 826286245\n",
      "...300 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 631074764216360959\n",
      "...385 tweets downloaded so far\n",
      "getting tweets before 626763214273953791\n",
      "...580 tweets downloaded so far\n",
      "getting tweets before 624227044981784576\n",
      "...780 tweets downloaded so far\n",
      "getting tweets before 623661250300370943\n",
      "...976 tweets downloaded so far\n",
      "getting tweets before 622303232090505215\n",
      "...1175 tweets downloaded so far\n",
      "getting tweets before 621116079205519363\n",
      "...1375 tweets downloaded so far\n",
      "getting tweets before 620221061376770048\n",
      "...1574 tweets downloaded so far\n",
      "getting tweets before 615042633384112127\n",
      "...1771 tweets downloaded so far\n",
      "getting tweets before 608602990916714496\n",
      "...1971 tweets downloaded so far\n",
      "getting tweets before 598469040793747456\n",
      "...2171 tweets downloaded so far\n",
      "getting tweets before 574525157097627647\n",
      "...2371 tweets downloaded so far\n",
      "getting tweets before 558208984792825857\n",
      "...2568 tweets downloaded so far\n",
      "getting tweets before 554232924128571392\n",
      "...2763 tweets downloaded so far\n",
      "getting tweets before 551004420670902271\n",
      "...2960 tweets downloaded so far\n",
      "getting tweets before 549484101439201279\n",
      "...3157 tweets downloaded so far\n",
      "getting tweets before 547162728146542592\n",
      "...3164 tweets downloaded so far\n",
      "getting tweets before 547011601614659584\n",
      "...3164 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 676343350732148735\n",
      "...3 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 676343350732148735\n",
      "...3 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 773838970392289280\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 656827987225157631\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 574972530236129281\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 499492755614498815\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 430747886918586367\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 309278936314044415\n",
      "...1297 tweets downloaded so far\n",
      "getting tweets before 167214732242194431\n",
      "...1297 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 1737993806\n",
      "...67 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 886887571564920832\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 881142956400496639\n",
      "...598 tweets downloaded so far\n",
      "getting tweets before 875978877054709759\n",
      "...798 tweets downloaded so far\n",
      "getting tweets before 870611978770948095\n",
      "...997 tweets downloaded so far\n",
      "getting tweets before 864911123694342143\n",
      "...1197 tweets downloaded so far\n",
      "getting tweets before 860126409968291846\n",
      "...1397 tweets downloaded so far\n",
      "getting tweets before 854757016325193732\n",
      "...1595 tweets downloaded so far\n",
      "getting tweets before 849333626504400899\n",
      "...1795 tweets downloaded so far\n",
      "getting tweets before 844544853472165887\n",
      "...1995 tweets downloaded so far\n",
      "getting tweets before 839520160448987135\n",
      "...2195 tweets downloaded so far\n",
      "getting tweets before 834428180110901247\n",
      "...2394 tweets downloaded so far\n",
      "getting tweets before 829778184535162879\n",
      "...2592 tweets downloaded so far\n",
      "getting tweets before 824745034411016192\n",
      "...2792 tweets downloaded so far\n",
      "getting tweets before 821078728260419583\n",
      "...2989 tweets downloaded so far\n",
      "getting tweets before 816678092475338751\n",
      "...3188 tweets downloaded so far\n",
      "getting tweets before 809857964605575167\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 809711857716105215\n",
      "...3199 tweets downloaded so far\n",
      "done\n",
      "getting tweets before 876482649107423231\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 864860622537850880\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 844267618445905919\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 827571338093162495\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 807533069284610051\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 789820151441096707\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 748441466620493823\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 706839117875843072\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 668795726315585535\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 639510111313133567\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 583594992721092608\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 519834369809469440\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 458976552597065727\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 382121155307773951\n",
      "...2998 tweets downloaded so far\n",
      "getting tweets before 276464589024133120\n",
      "...3198 tweets downloaded so far\n",
      "getting tweets before 164662882506768384\n",
      "...3230 tweets downloaded so far\n",
      "getting tweets before 136568703834791936\n",
      "...3230 tweets downloaded so far\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for user in users.Twitter[394:]:\n",
    "    if __name__ == '__main__':\n",
    "        try:\n",
    "    #pass in the username of the account you want to download\n",
    "            get_all_tweets(user)\n",
    "        except:\n",
    "            print ('error at %s ' %user)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>dbauder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Twitter\n",
       "394  dbauder"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#users[users=='westcoast_uk']\n",
    "users.iloc[np.where(users=='dbauder')]\n",
    "#users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aspenpharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insidecitywest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>westovergroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pontaragrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DraytonGroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alpha_LSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LauraAshleyUK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>berrygardensltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sandicliffe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AbantuM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bibendumwine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PorscheRetail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Brammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>API_News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cromwell_Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ralphlauren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AGCOcorp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AgnewVolkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>barrettsteel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nisbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CP_News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WyevaleGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>heronfoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vertumotors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FreshDirectUK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>generalmills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>madhavanbacardi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Abbott_Labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>CurtisHolt10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>ArlaFoodsUK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>harrismonkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>totalworldfresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>fayrefield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>phoenixcar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>MyFreshVape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Countrywide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>puma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>evanscycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>HALLIWELLJONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>FishBrothersLtd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>OfficeTeam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>findyrPath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>AvantiGas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>BeFuelcards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Joulesclothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>clarins_uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>blacks_online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>in_vino_nyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>BoutinotWines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>newell_brands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>BMWIreland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>CyT_UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>frontlinepbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Yoplait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>IKEAIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>FairchildSemi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>unifiedgrocers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Peter_Barfoots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Twitter\n",
       "0        aspenpharma\n",
       "1     insidecitywest\n",
       "2      westovergroup\n",
       "3       Pontaragrain\n",
       "4       DraytonGroup\n",
       "5               Coty\n",
       "6          Alpha_LSG\n",
       "7      LauraAshleyUK\n",
       "8    berrygardensltd\n",
       "9        sandicliffe\n",
       "10           AbantuM\n",
       "11      bibendumwine\n",
       "12     PorscheRetail\n",
       "13           Brammer\n",
       "14          API_News\n",
       "15    Cromwell_Tools\n",
       "16       ralphlauren\n",
       "17            people\n",
       "18          AGCOcorp\n",
       "19   AgnewVolkswagen\n",
       "20      barrettsteel\n",
       "21           Nisbets\n",
       "22           CP_News\n",
       "23         WyevaleGC\n",
       "24        heronfoods\n",
       "25       vertumotors\n",
       "26     FreshDirectUK\n",
       "27      generalmills\n",
       "28   madhavanbacardi\n",
       "29       Abbott_Labs\n",
       "..               ...\n",
       "228     CurtisHolt10\n",
       "229      ArlaFoodsUK\n",
       "230     harrismonkey\n",
       "231  totalworldfresh\n",
       "232       fayrefield\n",
       "233       phoenixcar\n",
       "234      MyFreshVape\n",
       "235      Countrywide\n",
       "236             puma\n",
       "237      evanscycles\n",
       "238   HALLIWELLJONES\n",
       "239  FishBrothersLtd\n",
       "240       OfficeTeam\n",
       "241       findyrPath\n",
       "242        AvantiGas\n",
       "243      BeFuelcards\n",
       "244   Joulesclothing\n",
       "245       clarins_uk\n",
       "246    blacks_online\n",
       "247      in_vino_nyc\n",
       "248    BoutinotWines\n",
       "249    newell_brands\n",
       "250       BMWIreland\n",
       "251           CyT_UK\n",
       "252     frontlinepbs\n",
       "253          Yoplait\n",
       "254           IKEAIE\n",
       "255    FairchildSemi\n",
       "256   unifiedgrocers\n",
       "257   Peter_Barfoots\n",
       "\n",
       "[258 rows x 1 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
